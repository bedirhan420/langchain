from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder
from langchain_huggingface.llms import HuggingFacePipeline
from langchain_core.output_parsers import StrOutputParser
from langchain_core.chat_history import BaseChatMessageHistory,InMemoryChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
from transformers import pipeline
import uuid
'''
YAPI 

model => transformer pipeline ile modeli oluÅŸturuyoz (HF)

sezon_id => geÃ§miÅŸi kaydetmek iÃ§in bir deÄŸiÅŸken ve sezon_id yi tanÄ±mlamak iÃ§in 
    eÄŸer yoksa InMemoryChatMessageHistory ile oluÅŸturuyoz ve dÃ¶nen tip BaseChatMesaageHsistory
    
promt_template => input_variable larÄ± ve prompt_texti tanÄ±mlÄ±yoz 
    MessagePlaceHolder ile historyyi veriyoz

parser => StrOutputParser ile parserÄ± oluÅŸturuyoz bu bize sadece istediÄŸimiz sonucu (content) veriyo

zincir => LCEL ile | zinciri oluÅŸturuyoz

geÃ§miÅŸ zinciri => RunnableWÄ°thMessageHistory ile 
    zinciri , sezonidyi oluÅŸturan fonksiyonu ve parameetreleri giriyoz
'''

flan_pipeline = pipeline(
    "text2text-generation",
    model="google/flan-t5-large",
    tokenizer="google/flan-t5-large",
    device=-1,
    max_length=500
)

model = HuggingFacePipeline(pipeline=flan_pipeline)

store = {}

def get_session_history(session_id:str)->BaseChatMessageHistory:
    if session_id not in store:
        store[session_id] = InMemoryChatMessageHistory()
    return store[session_id]


prompt_template = ChatPromptTemplate.from_messages([
    ("system", 
    "You are a helpful AI assistant. When a product review is given, analyze its sentiment (positive, neutral, negative)"
    "If asked about previous reviews, answer accordingly in full sentences.\n"
    "Always respond in this format:\n"
    "Sentiment: <positive/neutral/negative>\n"
    "Explanation: <brief explanation>"),
    MessagesPlaceholder(variable_name="history"),
    ("human", "{input}")
])

str_parser = StrOutputParser()

chain = prompt_template | model | str_parser

history_chain = RunnableWithMessageHistory(
    chain,
    get_session_history,
    input_messages_key="input",
    history_messages_key="history"
)

def interact(session_id: str, user_input: str):
    inputs = {
        "input": user_input
    }
    config = {"configurable": {"session_id": session_id}}
    try:
        result = history_chain.invoke(inputs, config=config)
        return result.strip()
    except Exception as e:
        return f"Analiz hatasÄ±: {e}"


def main():
    print("ÃœrÃ¼n Yorumu Analiz ve Puanlama")
    print("Ã‡Ä±kmak iÃ§in 'quit' yazabilirsiniz.\n")
    session_id = str(uuid.uuid4())
    print(f"Oturum ID'niz: {session_id}\n")
    
    while True:
        user_input= input("YOU : ").strip()
        if user_input.lower() == "quit":
            break
        if not user_input :
            print("Input boÅŸ olamaz.\n")
            continue
        
        result = interact(session_id,user_input)
        print(f"ðŸ¤– Asistan: {result}\n")

if __name__ == "__main__":
    main()
